{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e947fc6a-f3e0-4b8a-af58-827ee8a8d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.2.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pandas import DataFrame\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18002683-6aa9-426a-9a9f-51c69b700136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzeus0007\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">silver-plasma-24</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/zeus0007/img-classification-38\" target=\"_blank\">https://wandb.ai/zeus0007/img-classification-38</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/zeus0007/img-classification-38/runs/2eq8u4vl\" target=\"_blank\">https://wandb.ai/zeus0007/img-classification-38/runs/2eq8u4vl</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/wandb/run-20210830_022840-2eq8u4vl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_list=['resnext50_32x4d','resnext101_32x8d','vit_base_patch16_224','my_model','vgg16']\n",
    "wandb.init(project='img-classification-38', entity='zeus0007',config = {\n",
    "    'learning_rate':0.01,\n",
    "    'batch_size':64,\n",
    "    'epoch':30,\n",
    "    'model':'resnext50_32x4d',\n",
    "})\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e1c93a-bc16-4dc8-9606-1904564d7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "TRAIN_MASK_PATH = {'label':'/opt/ml/input/data/train/train.csv','images':'/opt/ml/input/data/train/images','new':'/opt/ml/input/data/train/new_train.csv'}\n",
    "TEST_MASK_PATH = '/input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ceb102-4eeb-4910-b8f0-5ecd92b2cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make transforms\n",
    "#넣을것 리사이즈, 좌우반전, shiftscalerotate, 가우시안 노이즈, 노말라이즈\n",
    "# 내가 설정한것 : transform 종류 & 얼만큼빈도로 적용할건지, 노말라이즈 정도는 얼마로 할건지\n",
    "# albumentations넣을건지\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "def transforms(train=True, img_size=(256, 192), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "    if train:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(img_size[0], img_size[1], p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            A.GaussNoise(p=0.5),\n",
    "            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(img_size[0], img_size[1]),\n",
    "            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fbf10b-cfe6-43d7-a460-9e71eda41c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODOS:데이터셋 만들기\n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, path,train=True):\n",
    "        # TODOS:csv 가져오기\n",
    "        data = pd.read_csv(path['new'])\n",
    "        image_path = data['abs_path']\n",
    "        \n",
    "        self.classified_labels = data['class']\n",
    "        self.images_full_path = image_path\n",
    "        \n",
    "#         self.images = np.array([Image.open(image_full_path) for image_full_path in tqdm(images_full_path)])\n",
    "\n",
    "    def set_transform(self,transform):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images_full_path.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        image_path = self.images_full_path[idx]\n",
    "        image = Image.open('/opt/ml/'+image_path)\n",
    "        y = self.classified_labels[idx]\n",
    "        \n",
    "        X = self.transform(image=np.array(image))['image']\n",
    "        type(X)\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5e10c9-a3c8-4e9c-825e-d8e437e86e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7f94480eca00>\n"
     ]
    }
   ],
   "source": [
    "train_mask_dataset = MaskDataset(TRAIN_MASK_PATH, train=True)\n",
    "\n",
    "n_val = int(len(train_mask_dataset) * 0.2)\n",
    "n_train = len(train_mask_dataset) - n_val\n",
    "train_dataset, val_dataset = random_split(train_mask_dataset, [n_train, n_val])\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "train_dataset.dataset.set_transform(transforms(train=True))\n",
    "val_dataset.dataset.set_transform(transforms(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ea5b30-80a4-4507-87d3-e40b995ef4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18899"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mask_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81973507-25d7-46e8-8619-a4d32acfcae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.8482,  0.8482,  0.8482,  ...,  1.0137,  1.0137,  1.0137],\n",
       "          [ 0.8482,  0.8482,  0.8482,  ...,  1.0137,  1.0137,  1.0137],\n",
       "          [ 0.8482,  0.8482,  0.8482,  ...,  1.0137,  1.0137,  1.0137],\n",
       "          ...,\n",
       "          [ 0.2360,  0.2360,  0.2029,  ...,  0.0208,  0.0705,  0.1201],\n",
       "          [ 0.1863,  0.1863,  0.1532,  ...,  0.1036,  0.1532,  0.1698],\n",
       "          [ 0.0870,  0.0870,  0.0539,  ...,  0.1367,  0.2194,  0.2360]],\n",
       " \n",
       "         [[ 0.9761,  0.9761,  0.9761,  ...,  1.1349,  1.1349,  1.1349],\n",
       "          [ 0.9761,  0.9761,  0.9761,  ...,  1.1349,  1.1349,  1.1349],\n",
       "          [ 0.9761,  0.9761,  0.9761,  ...,  1.1349,  1.1349,  1.1349],\n",
       "          ...,\n",
       "          [-0.4211, -0.4211, -0.4528,  ..., -0.5957, -0.5481, -0.5163],\n",
       "          [-0.4687, -0.4687, -0.5004,  ..., -0.5798, -0.5481, -0.5481],\n",
       "          [-0.5639, -0.5639, -0.5957,  ..., -0.6116, -0.5481, -0.5322]],\n",
       " \n",
       "         [[ 1.0020,  1.0020,  1.0020,  ...,  1.1614,  1.1614,  1.1614],\n",
       "          [ 1.0020,  1.0020,  1.0020,  ...,  1.1614,  1.1614,  1.1614],\n",
       "          [ 1.0020,  1.0020,  1.0020,  ...,  1.1614,  1.1614,  1.1614],\n",
       "          ...,\n",
       "          [-0.9110, -0.9110, -0.9429,  ..., -1.1341, -1.1182, -1.1023],\n",
       "          [-0.9588, -0.9588, -0.9907,  ..., -1.0066, -0.9907, -0.9907],\n",
       "          [-1.0544, -1.0544, -1.0863,  ..., -0.8791, -0.8153, -0.8153]]]),\n",
       " 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356dce2d-fb9b-4e93-91e3-a8eb928437cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e273965-7ffc-4d84-bb39-34f43fccddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, mid_dim,out_dim, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=1, padding=0, bias=False, stride=1),\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, mid_dim, kernel_size=1, padding=0, bias=False, stride=1),\n",
    "            nn.BatchNorm2d(mid_dim),\n",
    "            nn.ReLU(inplace= True),\n",
    "            nn.Conv2d(mid_dim, out_dim, kernel_size=3, padding=1, bias=False, stride=1),\n",
    "            nn.BatchNorm2d(out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "    \n",
    "def make_layer(in_dim, mid_dim, out_dim, repeats, starting=False):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(in_dim, mid_dim, out_dim))\n",
    "        for _ in range(1, repeats):\n",
    "            layers.append(BasicBlock(out_dim, mid_dim, out_dim))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        base_dim = 64\n",
    "        self.conv2_x = make_layer(base_dim, 32, base_dim, 1)\n",
    "        self.s_conv1 = self.simple_conv(base_dim, base_dim*2)\n",
    "        self.conv3_x = make_layer(base_dim*2, base_dim, base_dim*2, 2)\n",
    "        self.s_conv2 = self.simple_conv(base_dim*2, base_dim*4)\n",
    "        self.conv4_x = make_layer(base_dim*4, base_dim*2, base_dim*4, 8)\n",
    "        self.s_conv3 = self.simple_conv(base_dim*4, base_dim*8)\n",
    "        self.conv5_x = make_layer(base_dim*8, base_dim*4, base_dim*8, 8)\n",
    "        self.s_conv4 = self.simple_conv(base_dim*8, base_dim*16)\n",
    "        self.conv6_x = make_layer(base_dim*16, base_dim*8, base_dim*16, 4)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def simple_conv(self, in_dim, out_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(inplace= True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.s_conv1(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.s_conv2(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.s_conv3(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.s_conv4(output)\n",
    "        output = self.conv6_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9d1e34-2a7d-4980-a8e5-bedaff4b99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_model(model):\n",
    "    if model == 'resnext50_32x4d':\n",
    "        return models.resnext50_32x4d(pretrained=True).to(device)\n",
    "    elif model == 'my_model':\n",
    "        return ResNet(18).to(device)\n",
    "    elif model == 'resnext101_32x8d':\n",
    "        return models.resnext101_32x8d(pretrained=True).to(device)\n",
    "    elif model == 'vit_base_patch16_224':\n",
    "        return timm.create_model('vit_base_patch16_224',pretrained=True).to(device)\n",
    "    elif model == 'vgg16':\n",
    "        return models.vgg16(pretrained=True).to(device)\n",
    "    elif model == 'resnet156':\n",
    "        return models.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d841459f-9c20-4548-89b8-fd6db4b90106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "model = config_model(config.model)\n",
    "num_features = model.fc.in_features\n",
    "print(num_features)\n",
    "model.fc = nn.Linear(num_features, 18).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418cf85b-111a-443e-9335-c76e22152365",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = config.learning_rate\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "image_datasets = {\n",
    "    'train':train_dataset,\n",
    "    'validation':val_dataset}\n",
    "dataloaders = {'train':train_loader, 'validation':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81710f19-4dee-44e9-9779-a9fb2492bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "            wandb.log({f\"{phase}_acc\":epoch_acc, f\"{phase}_loss\":epoch_loss})\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15839414-70fc-45ae-b6ec-07b02df1110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b9581-4f82-48a8-89c3-77d681712b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23907bfdae914bce865e050f04dd2ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 2.3973, acc: 0.2610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7caaf8b07cf4aa5bb3f8abbdc8305c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 2.0120, acc: 0.3289\n",
      "Epoch 2/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55d3531a8b64a2da7c771a0b7a7f838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 1.4206, acc: 0.5006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ea86d9b8d1421595f50c8631aae040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 1.6418, acc: 0.4962\n",
      "Epoch 3/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d753e5945c4eeab5c156abad09187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.8681, acc: 0.6946\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65663bd34f81487b809ad873d1e8eb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.8197, acc: 0.7184\n",
      "Epoch 4/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9febc0fc67049e8ad4c17730010066d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.6733, acc: 0.7555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5514cef66d24406a8ce88fc1f173e6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 1.0951, acc: 0.6311\n",
      "Epoch 5/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038def679fed480384ae079c6f73de3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.5589, acc: 0.7921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b30987414ed46c7866d7df6dc463ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.6038, acc: 0.7835\n",
      "Epoch 6/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6c2c908ebf4d2a9c314aae4dc3a271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.4746, acc: 0.8250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1dfc7475af4aa3a8ecdad40837bf5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.6586, acc: 0.7732\n",
      "Epoch 7/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bca45672524596b148105fbb879e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.4011, acc: 0.8488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae2c01544084779909b06c551dd3440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.6935, acc: 0.7753\n",
      "Epoch 8/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a462018fe39d410c81c058e37435891e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.3694, acc: 0.8631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4dd387ae99484086901b96273d95f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.7066, acc: 0.7716\n",
      "Epoch 9/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243bc699250c47d9b48c9002079973c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.3198, acc: 0.8780\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07a2780ce20417282116246b9ae7699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.9716, acc: 0.6827\n",
      "Epoch 10/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d78d36a411b4c48bb0f72a4c02d7da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.2827, acc: 0.8935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9dc157cebaa48cb9fc2eade87c82e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.5944, acc: 0.8076\n",
      "Epoch 11/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0ae182fbdf4cdbb88b44f98b60c51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.2702, acc: 0.8976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083b716dfde64a969c316197fa35c793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.5728, acc: 0.8185\n",
      "Epoch 12/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3870c0f1b38d4990ac651f1964f62784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.2445, acc: 0.9086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a003934929454b0ebf1ecde0c1248556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss: 0.3926, acc: 0.8550\n",
      "Epoch 13/30\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b885125ecd749a58a8c9f7f08c61bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model = train_model(model, criterion, optimizer, num_epochs=config.epoch)\n",
    "model.eval()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d6577-7a38-4640-9d94-6f47736b2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1f7b3-8143-4380-a0e9-196da0fbf185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981a222-9957-48ae-90ec-1204e2d5b2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b2f17-84ef-4960-bb16-b6bec4e0ca64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
